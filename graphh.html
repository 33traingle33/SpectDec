<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dynamic Spectrograph</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for better visual appeal and responsiveness */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #1a202c; /* Dark background */
            color: #e2e8f0; /* Light text */
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            padding: 1rem;
        }
        .container {
            background-color: #2d3748; /* Slightly lighter dark background for container */
            border-radius: 0.75rem; /* Rounded corners */
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05); /* Subtle shadow */
            padding: 2rem;
            width: 100%;
            max-width: 960px; /* Max width for desktop */
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
        }
        canvas {
            background-color: #000; /* Black background for spectrograph */
            border-radius: 0.5rem;
            width: 100%; /* Make canvas responsive */
            height: 400px; /* Fixed height for the spectrograph */
            border: 1px solid #4a5568;
        }
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #63b3ed; /* Blue thumb */
            cursor: pointer;
            box-shadow: 0 0 0 3px rgba(99, 179, 237, 0.5);
            margin-top: -6px; /* Adjust thumb position */
        }
        input[type="range"]::-moz-range-thumb {
            width: 16px;
            height: 16px;
            border-radius: 50%;
            background: #63b3ed;
            cursor: pointer;
            box-shadow: 0 0 0 3px rgba(99, 179, 237, 0.5);
        }
        input[type="range"] {
            -webkit-appearance: none;
            width: 100%;
            height: 4px;
            background: #4a5568; /* Slider track color */
            outline: none;
            opacity: 0.7;
            transition: opacity .2s;
            border-radius: 2px;
        }
        input[type="range"]:hover {
            opacity: 1;
        }
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
        }
        .control-group label {
            font-weight: bold;
            color: #a0aec0;
        }
        .control-group span {
            font-size: 0.875rem;
            color: #cbd5e0;
        }
        .record-button.recording {
            background-color: #ef4444; /* Red for recording */
            animation: pulse 1s infinite alternate;
        }
        @keyframes pulse {
            from { transform: scale(1); opacity: 1; }
            to { transform: scale(1.02); opacity: 0.8; }
        }
        .freq-input-group {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .freq-input-group input[type="number"] {
            width: 80px; /* Fixed width for number input */
            padding: 0.5rem;
            border-radius: 0.375rem;
            border: 1px solid #4a5568;
            background-color: #2d3748;
            color: #e2e8f0;
            text-align: center;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100 flex items-center justify-center min-h-screen p-4">
    <div class="container bg-gray-800 rounded-xl shadow-lg p-8 flex flex-col gap-6">
        <h1 class="text-3xl font-extrabold text-center text-blue-400 mb-4">Dynamic Audio Spectrograph</h1>

        <div class="flex flex-col items-center gap-4">
            <label for="audioFile" class="block text-lg font-medium text-gray-300">Upload Audio File:</label>
            <input type="file" id="audioFile" accept="audio/*" class="w-full max-w-md p-3 border border-gray-600 rounded-lg bg-gray-700 text-gray-200 cursor-pointer hover:border-blue-500 transition duration-300 ease-in-out">
            <div class="flex justify-center gap-4 w-full max-w-md">
                <button id="playSelectedAudioBtn" class="flex-1 p-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition duration-300 ease-in-out" disabled>
                    Play / Pause Audio
                </button>
                <button id="startMicrophone" class="flex-1 p-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition duration-300 ease-in-out">
                    Record from Microphone
                </button>
            </div>
            <p id="statusMessage" class="text-sm text-gray-400 mt-2">Please upload an audio file or record from microphone to begin.</p>
        </div>

        <div class="flex flex-col gap-4 mt-4 p-4 bg-gray-700 rounded-lg">
            <h2 class="text-xl font-bold text-gray-200 text-center">Audio Playback Controls</h2>
            <div class="control-group">
                <label for="volumeSlider">Volume:</label>
                <input type="range" id="volumeSlider" min="0" max="1" value="0.7" step="0.01">
                <span id="volumeValue" class="text-right">70%</span>
            </div>
            <div class="control-group">
                <label for="seekBar">Progress:</label>
                <input type="range" id="seekBar" min="0" max="100" value="0" step="0.1" disabled>
                <span id="progressTime" class="text-right">0:00 / 0:00</span>
            </div>
        </div>

        <div class="flex justify-center gap-4 mt-4">
            <button id="startRecording" class="px-6 py-3 bg-green-600 text-white rounded-lg hover:bg-green-700 transition duration-300 ease-in-out record-button">
                Start Recording
            </button>
            <button id="stopRecording" class="px-6 py-3 bg-red-600 text-white rounded-lg hover:bg-red-700 transition duration-300 ease-in-out" disabled>
                Stop Recording
            </button>
            <button id="saveSpectrogramBtn" class="px-6 py-3 bg-purple-600 text-white rounded-lg hover:bg-purple-700 transition duration-300 ease-in-out">
                Save Spectrogram Image
            </button>
            <button id="stopAllAudioBtn" class="px-6 py-3 bg-gray-600 text-white rounded-lg hover:bg-gray-700 transition duration-300 ease-in-out" disabled>
                Stop All Audio
            </button>
        </div>

        <div class="text-center text-2xl font-bold text-yellow-300 mt-4">
            Detected Note: <span id="detectedNote">N/A</span>
        </div>

        <canvas id="spectrographCanvas" class="rounded-lg border border-gray-700"></canvas>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mt-4">
            <div class="control-group">
                <label for="minFreq">Minimum Frequency:</label>
                <div class="freq-input-group">
                    <input type="range" id="minFreq" min="0" max="20000" value="0" step="10">
                    <input type="number" id="minFreqNumber" min="0" max="20000" value="0" step="10">
                    <span id="minFreqValue" class="text-right">Hz</span>
                </div>
            </div>
            <div class="control-group">
                <label for="maxFreq">Maximum Frequency:</label>
                <div class="freq-input-group">
                    <input type="range" id="maxFreq" min="0" max="20000" value="20000" step="10">
                    <input type="number" id="maxFreqNumber" min="0" max="20000" value="20000" step="10">
                    <span id="maxFreqValue" class="text-right">Hz</span>
                </div>
            </div>
        </div>

        <div class="flex justify-center gap-4 mt-4">
            <button id="setA432HzBtn" class="px-6 py-3 bg-indigo-600 text-white rounded-lg hover:bg-indigo-700 transition duration-300 ease-in-out">
                Set Freq to A4=432 Hz
            </button>
            <button id="toggleOverlayBtn" class="px-6 py-3 bg-teal-600 text-white rounded-lg hover:bg-teal-700 transition duration-300 ease-in-out">
                Toggle Overlay
            </button>
        </div>

        <div id="messageBox" class="hidden fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
            <div class="bg-gray-700 p-6 rounded-lg shadow-xl text-center flex flex-col items-center gap-4">
                <p id="messageText" class="text-lg text-gray-100"></p>
                <button id="closeMessageBox" class="px-6 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 transition duration-300 ease-in-out">OK</button>
            </div>
        </div>
    </div>

    <script>
        // Get DOM elements
        const audioFile = document.getElementById('audioFile');
        const playSelectedAudioBtn = document.getElementById('playSelectedAudioBtn');
        const startMicrophoneBtn = document.getElementById('startMicrophone');
        const startRecordingBtn = document.getElementById('startRecording');
        const stopRecordingBtn = document.getElementById('stopRecording');
        const saveSpectrogramBtn = document.getElementById('saveSpectrogramBtn');
        const stopAllAudioBtn = document.getElementById('stopAllAudioBtn');
        const spectrographCanvas = document.getElementById('spectrographCanvas');
        const minFreqSlider = document.getElementById('minFreq');
        const maxFreqSlider = document.getElementById('maxFreq');
        const minFreqNumberInput = document.getElementById('minFreqNumber');
        const maxFreqNumberInput = document.getElementById('maxFreqNumber');
        const minFreqValueSpan = document.getElementById('minFreqValue');
        const maxFreqValueSpan = document.getElementById('maxFreqValue');
        const statusMessage = document.getElementById('statusMessage');
        const detectedNoteSpan = document.getElementById('detectedNote');
        const setA432HzBtn = document.getElementById('setA432HzBtn');
        const toggleOverlayBtn = document.getElementById('toggleOverlayBtn');
        const volumeSlider = document.getElementById('volumeSlider'); // New
        const volumeValueSpan = document.getElementById('volumeValue'); // New
        const seekBar = document.getElementById('seekBar'); // New
        const progressTimeSpan = document.getElementById('progressTime'); // New
        const messageBox = document.getElementById('messageBox');
        const messageText = document.getElementById('messageText');
        const closeMessageBox = document.getElementById('closeMessageBox');

        // Canvas context
        const ctx = spectrographCanvas.getContext('2d');

        // AudioContext and nodes
        let audioContext;
        let analyser;
        let gainNode; // New for volume control
        let fileSource = null;
        let micSource = null;
        let mediaStream = null;
        let mediaRecorder = null;
        let recordedChunks = [];
        let isRecording = false;
        let selectedAudioFile = null;
        let isOverlayVisible = true;
        let audioBuffer = null; // Store the decoded audio buffer for seeking
        let playbackTime = 0; // Current playback position in seconds
        let startTime = 0;    // AudioContext.currentTime when playback started
        let isPlayingFile = false; // Flag to track if file is playing
        let isPaused = false; // Flag to track if file playback is paused

        // Spectrograph data buffer
        let spectrographBuffer = [];
        let animationFrameId;

        // Musical note mapping
        const noteNames = ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"];
        const A4_FREQUENCY = 432; // A4 note is 432 Hz

        // --- Configurable Settings for Dominant Note Indicator ---
        let dominantFreqLineColor = '#FFD700'; // Gold color
        let dominantFreqLineWidth = 1.5;
        let dominantFreqLabelColor = '#FFD700'; // Gold text
        let dominantFreqLabelFont = 'bold 14px Inter'; // Larger and bold font
        let dominantFreqLabelOffsetX = -5; // Offset from right edge
        let dominantFreqLabelOffsetY = -5; // Offset from the line itself
        // --- End Configurable Settings ---

        // Helper to format time (seconds to MM:SS)
        function formatTime(seconds) {
            const minutes = Math.floor(seconds / 60);
            const remainingSeconds = Math.floor(seconds % 60);
            return `${minutes}:${remainingSeconds < 10 ? '0' : ''}${remainingSeconds}`;
        }

        // Function to convert frequency to musical note
        function getNoteFromFrequency(frequency) {
            if (frequency <= 0) return "N/A";

            const semitonesFromA4 = 12 * Math.log2(frequency / A4_FREQUENCY);
            const roundedSemitones = Math.round(semitonesFromA4);
            const noteIndex = (9 + roundedSemitones % 12 + 12) % 12;
            const octave = Math.floor(4 + (roundedSemitones + 9) / 12);

            return noteNames[noteIndex] + octave;
        }

        // Function to show custom message box
        function showMessageBox(message) {
            messageText.textContent = message;
            messageBox.classList.remove('hidden');
        }

        // Close message box
        closeMessageBox.addEventListener('click', () => {
            messageBox.classList.add('hidden');
        });

        // Initialize AudioContext and core nodes
        function initAudioContext() {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                gainNode = audioContext.createGain(); // Initialize GainNode
                analyser.connect(gainNode); // Connect analyser to gainNode
                gainNode.connect(audioContext.destination); // Connect gainNode to speakers
                volumeSlider.value = gainNode.gain.value; // Set slider to initial gain
                volumeValueSpan.textContent = `${Math.round(gainNode.gain.value * 100)}%`;
            }
        }

        // Function to stop all active audio sources and recording
        function stopAllSources() {
            if (fileSource) {
                fileSource.stop();
                fileSource.disconnect();
                fileSource = null;
            }
            if (micSource) {
                micSource.disconnect();
                micSource = null;
            }
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            if (isRecording && mediaRecorder) {
                mediaRecorder.stop();
                isRecording = false;
                startRecordingBtn.classList.remove('recording');
            }
            // Clear canvas and buffer when stopping sources
            ctx.clearRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
            ctx.fillStyle = '#000';
            ctx.fillRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
            detectedNoteSpan.textContent = 'N/A';
            spectrographBuffer = []; // Clear the buffer

            // Reset playback state for file audio
            isPlayingFile = false;
            isPaused = false;
            playbackTime = 0;
            startTime = 0;
            seekBar.value = 0;
            progressTimeSpan.textContent = `0:00 / ${audioBuffer ? formatTime(audioBuffer.duration) : '0:00'}`;

            // Disable relevant buttons
            startRecordingBtn.disabled = true;
            stopRecordingBtn.disabled = true;
            stopAllAudioBtn.disabled = true;
            playSelectedAudioBtn.disabled = (selectedAudioFile === null);
            playSelectedAudioBtn.textContent = 'Play / Pause Audio'; // Reset button text
            seekBar.disabled = true; // Disable seek bar
            statusMessage.textContent = 'Ready for new input.';
        }

        // Function to play audio from file (or resume)
        function playAudioFile(offset = 0) {
            if (!audioBuffer) {
                showMessageBox('No audio file loaded to play.');
                return;
            }

            stopAllSources(); // Stop current playback/mic before starting file
            initAudioContext(); // Ensure context is ready

            fileSource = audioContext.createBufferSource();
            fileSource.buffer = audioBuffer;

            // Connect to analyser and then to gainNode for volume control
            fileSource.connect(analyser);
            analyser.connect(gainNode); // Ensure analyser output goes to gainNode
            gainNode.connect(audioContext.destination); // Ensure gainNode connects to destination

            fileSource.loop = false; // Don't loop by default, can be added as an option later
            
            // Set up onended event to reset playback state
            fileSource.onended = () => {
                if (isPlayingFile) { // Only if it was playing and not manually stopped
                    stopAllSources(); // Reset everything when audio ends
                    statusMessage.textContent = `Finished playing: ${selectedAudioFile.name}.`;
                    playSelectedAudioBtn.textContent = 'Play / Pause Audio';
                }
            };

            // Start playback from offset
            startTime = audioContext.currentTime - offset; // Calculate true start time
            fileSource.start(0, offset); // Start playing from 'offset' seconds into the buffer

            isPlayingFile = true;
            isPaused = false;
            playbackTime = offset; // Update playbackTime
            statusMessage.textContent = `Playing from file: ${selectedAudioFile.name}`;
            playSelectedAudioBtn.textContent = 'Pause Audio';
            startRecordingBtn.disabled = false;
            stopAllAudioBtn.disabled = false;
            seekBar.disabled = false; // Enable seek bar
            seekBar.max = audioBuffer.duration; // Set seek bar max to duration
            progressTimeSpan.textContent = `${formatTime(playbackTime)} / ${formatTime(audioBuffer.duration)}`;
            updateSpectrograph(); // Start visualization
        }

        // Function to pause audio from file
        function pauseAudioFile() {
            if (fileSource && isPlayingFile && !isPaused) {
                fileSource.stop();
                fileSource.disconnect();
                fileSource = null;
                // Calculate current playback time
                playbackTime += (audioContext.currentTime - startTime);
                isPaused = true;
                isPlayingFile = false;
                statusMessage.textContent = `Paused: ${selectedAudioFile.name}`;
                playSelectedAudioBtn.textContent = 'Play / Pause Audio';
                // Keep spectrograph running to show last frame or clear
                // For now, let it continue until stopAllSources is called.
            }
        }

        // Function to toggle play/pause for file audio
        function togglePlayPauseFile() {
            if (!selectedAudioFile) {
                showMessageBox('Please upload an audio file first.');
                return;
            }
            if (!audioBuffer) { // If file selected but not yet decoded
                loadAndPlayAudio(selectedAudioFile); // This will decode and then play
            } else if (isPlayingFile) {
                pauseAudioFile();
            } else { // If paused or not playing
                playAudioFile(playbackTime); // Resume from current playbackTime
            }
        }

        // Function to load audio file (decodes it, but doesn't auto-play)
        async function loadAudioFile(file) {
            stopAllSources(); // Clear previous state
            initAudioContext();

            statusMessage.textContent = 'Decoding audio file...';
            try {
                const arrayBuffer = await file.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                selectedAudioFile = file; // Store the file object
                
                // Reset playback state for new file
                playbackTime = 0;
                startTime = 0;
                isPlayingFile = false;
                isPaused = false;

                statusMessage.textContent = `File loaded: ${file.name}. Click 'Play / Pause Audio' to start.`;
                playSelectedAudioBtn.disabled = false; // Enable play button
                startRecordingBtn.disabled = true; // Recording only enabled when audio is playing
                stopAllAudioBtn.disabled = true;
                seekBar.disabled = true; // Disable seek bar until playing
                seekBar.max = audioBuffer.duration; // Set max for duration
                seekBar.value = 0; // Reset seek bar
                progressTimeSpan.textContent = `0:00 / ${formatTime(audioBuffer.duration)}`;
                detectedNoteSpan.textContent = 'N/A';
                spectrographBuffer = []; // Clear buffer for new file
            } catch (error) {
                console.error('Error decoding audio file:', error);
                statusMessage.textContent = 'Error decoding audio file.';
                showMessageBox('Failed to decode audio file. Please try a different format or file.');
                selectedAudioFile = null;
                audioBuffer = null;
                playSelectedAudioBtn.disabled = true;
                startRecordingBtn.disabled = true;
                stopAllAudioBtn.disabled = true;
                seekBar.disabled = true;
                progressTimeSpan.textContent = `0:00 / 0:00`;
            }
        }


        // Function to start microphone input
        async function startMicrophone() {
            stopAllSources(); // Stop any existing audio or recording
            initAudioContext();

            statusMessage.textContent = 'Requesting microphone access...';

            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                micSource = audioContext.createMediaStreamSource(mediaStream);

                micSource.connect(analyser);
                // analyser.connect(audioContext.destination); // No direct connection, goes via gainNode
                analyser.connect(gainNode); // Connect analyser to gainNode
                gainNode.connect(audioContext.destination); // Ensure gainNode connects to destination

                statusMessage.textContent = 'Recording from microphone...';
                updateSpectrograph();
                startRecordingBtn.disabled = false;
                stopAllAudioBtn.disabled = false;
                playSelectedAudioBtn.disabled = true; // Disable play button when using mic
                seekBar.disabled = true; // Disable seek bar for mic
                progressTimeSpan.textContent = `Live / 0:00`;
            } catch (error) {
                console.error('Error accessing microphone:', error);
                statusMessage.textContent = 'Microphone access denied or no microphone found.';
                showMessageBox('Could not access microphone. Please ensure it is connected and permissions are granted.');
                startRecordingBtn.disabled = true;
                stopAllAudioBtn.disabled = true;
                playSelectedAudioBtn.disabled = (selectedAudioFile === null);
                seekBar.disabled = true;
                progressTimeSpan.textContent = `0:00 / 0:00`;
            }
        }

        // Function to start recording
        function startRecording() {
            if (!audioContext || (!fileSource && !micSource)) {
                showMessageBox('Please load an audio file or start microphone input first.');
                return;
            }

            recordedChunks = [];
            isRecording = true;
            startRecordingBtn.disabled = true;
            stopRecordingBtn.disabled = false;
            startRecordingBtn.classList.add('recording');
            statusMessage.textContent = 'Recording audio...';

            let streamToRecord;
            // Create a MediaStreamDestination to capture audio from the analyser
            const destination = audioContext.createMediaStreamDestination();
            analyser.connect(destination); // Connect analyser output to destination for recording
            streamToRecord = destination.stream;
            
            // Ensure the analyser is also connected to the gainNode for playback
            analyser.connect(gainNode);


            try {
                mediaRecorder = new MediaRecorder(streamToRecord);

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = () => {
                    const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a');
                    a.style.display = 'none';
                    a.href = url;
                    a.download = 'spectrograph_recording.webm';
                    document.body.appendChild(a);
                    a.click();
                    window.URL.revokeObjectURL(url);

                    isRecording = false;
                    startRecordingBtn.disabled = false;
                    stopRecordingBtn.disabled = true;
                    startRecordingBtn.classList.remove('recording');
                    statusMessage.textContent = 'Recording saved. Ready for new input.';

                    // Disconnect analyser from the recording destination
                    analyser.disconnect(destination);
                };

                mediaRecorder.start();
                statusMessage.textContent = 'Recording... (Click Stop Recording to save)';
            } catch (e) {
                console.error('Error starting MediaRecorder:', e);
                showMessageBox('Failed to start recording. Your browser might not support MediaRecorder or there\'s an issue with the audio stream.');
                isRecording = false;
                startRecordingBtn.disabled = false;
                stopRecordingBtn.disabled = true;
                startRecordingBtn.classList.remove('recording');
            }
        }

        // Function to stop recording
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
        }

        // Function to save the current spectrogram image
        function saveSpectrogramImage() {
            if (!spectrographCanvas || spectrographCanvas.width === 0 || spectrographCanvas.height === 0) {
                showMessageBox('No spectrogram data to save. Please play audio first.');
                return;
            }

            const finalCanvas = document.createElement('canvas');
            finalCanvas.width = spectrographCanvas.width;
            finalCanvas.height = spectrographCanvas.height;
            const finalCtx = finalCanvas.getContext('2d');

            finalCtx.fillStyle = '#000';
            finalCtx.fillRect(0, 0, finalCanvas.width, finalCanvas.height);

            const minFreq = parseFloat(minFreqSlider.value);
            const maxFreq = parseFloat(maxFreqSlider.value);
            const freqRangeHeight = maxFreq - minFreq;
            const pixelsPerHz = finalCanvas.height / freqRangeHeight;
            const frequencyResolution = audioContext.sampleRate / analyser.fftSize;

            spectrographBuffer.forEach((dataArray, x_pos) => {
                const minBin = Math.floor(minFreq / frequencyResolution);
                const maxBin = Math.ceil(maxFreq / frequencyResolution);
                const effectiveMinBin = Math.max(0, Math.min(minBin, dataArray.length - 1));
                const effectiveMaxBin = Math.min(dataArray.length - 1, Math.max(maxBin, effectiveMinBin));

                for (let i = effectiveMinBin; i <= effectiveMaxBin; i++) {
                    const freq = i * frequencyResolution;
                    const magnitude = dataArray[i];

                    let r = Math.floor(magnitude * 1);
                    let g = Math.floor(magnitude * 0.5);
                    let b = Math.floor(magnitude * 0.2);
                    finalCtx.fillStyle = `rgb(${r}, ${g}, ${b})`;

                    const y_start = finalCanvas.height - ((freq - minFreq) * pixelsPerHz);
                    const y_end = finalCanvas.height - (((freq + frequencyResolution) - minFreq) * pixelsPerHz);

                    const drawY = Math.min(y_start, y_end);
                    const drawHeight = Math.abs(y_start - y_end);

                    if (drawY + drawHeight > 0 && drawY < finalCanvas.height) {
                       finalCtx.fillRect(x_pos, drawY, 1, drawHeight);
                    }
                }
            });

            if (isOverlayVisible) {
                const tickFrequencies = [
                    50, 100, 200, 300, 400, 500, 600, 700, 800, 900,
                    1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000,
                    10000, 12000, 14000, 16000, 18000, 20000
                ];

                finalCtx.font = '12px Inter';
                finalCtx.fillStyle = '#a0aec0';
                finalCtx.strokeStyle = 'rgba(160, 174, 192, 0.3)';
                finalCtx.lineWidth = 0.5;

                tickFrequencies.forEach(freq => {
                    if (freq >= minFreq && freq <= maxFreq) {
                        const y_pos = finalCanvas.height - ((freq - minFreq) * pixelsPerHz);
                        if (y_pos >= 0 && y_pos <= finalCanvas.height) {
                            finalCtx.beginPath();
                            finalCtx.moveTo(0, y_pos);
                            finalCtx.lineTo(finalCanvas.width, y_pos);
                            finalCtx.stroke();
                            let label = freq + ' Hz';
                            if (freq >= 1000) {
                                label = (freq / 1000) + ' kHz';
                            }
                            finalCtx.textAlign = 'left';
                            finalCtx.fillText(label, 5, y_pos - 2);
                        }
                    }
                });

                if (detectedNoteSpan.textContent !== 'N/A' && spectrographBuffer.length > 0) {
                    const lastDataArray = spectrographBuffer[spectrographBuffer.length - 1];
                    let currentDominantFreq = 0;
                    let currentMaxMagnitude = 0;
                    const minBin = Math.floor(minFreq / frequencyResolution);
                    const maxBin = Math.ceil(maxFreq / frequencyResolution);
                    const effectiveMinBin = Math.max(0, Math.min(minBin, lastDataArray.length - 1));
                    const effectiveMaxBin = Math.min(lastDataArray.length - 1, Math.max(maxBin, effectiveMinBin));

                    for (let i = effectiveMinBin; i <= effectiveMaxBin; i++) {
                        const freq = i * frequencyResolution;
                        const magnitude = lastDataArray[i];
                        if (magnitude > currentMaxMagnitude) {
                            currentMaxMagnitude = magnitude;
                            currentDominantFreq = freq;
                        }
                    }

                    if (currentDominantFreq > 0 && currentMaxMagnitude > 0) {
                        const dominantFreqY = finalCanvas.height - ((currentDominantFreq - minFreq) * pixelsPerHz);
                        if (dominantFreqY >= 0 && dominantFreqY <= finalCanvas.height) {
                            finalCtx.strokeStyle = dominantFreqLineColor;
                            finalCtx.lineWidth = dominantFreqLineWidth;
                            finalCtx.beginPath();
                            finalCtx.moveTo(0, dominantFreqY);
                            finalCtx.lineTo(finalCanvas.width, dominantFreqY);
                            finalCtx.stroke();

                            finalCtx.fillStyle = dominantFreqLabelColor;
                            finalCtx.font = dominantFreqLabelFont;
                            finalCtx.textAlign = 'right';
                            finalCtx.fillText(`${getNoteFromFrequency(currentDominantFreq)}`, finalCanvas.width + dominantFreqLabelOffsetX, dominantFreqY + dominantFreqLabelOffsetY);
                        }
                    }
                }
            }

            const imageURI = finalCanvas.toDataURL('image/png');
            const a = document.createElement('a');
            a.href = imageURI;
            a.download = 'spectrogram_with_grid.png';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            showMessageBox('Spectrogram image with frequency grid saved as spectrogram_with_grid.png');
        }

        // Function to update spectrograph visualization
        function updateSpectrograph() {
            if (!analyser) return;

            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            analyser.getByteFrequencyData(dataArray);

            // Add new data to the buffer
            spectrographBuffer.push(dataArray);
            // If the buffer is larger than the canvas width, remove the oldest column
            if (spectrographBuffer.length > spectrographCanvas.width) {
                spectrographBuffer.shift();
            }

            ctx.clearRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
            ctx.fillStyle = '#000';
            ctx.fillRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);

            const minFreq = parseFloat(minFreqSlider.value);
            const maxFreq = parseFloat(maxFreqSlider.value);

            minFreqNumberInput.value = minFreq;
            maxFreqNumberInput.value = maxFreq;
            minFreqValueSpan.textContent = `${minFreq} Hz`;
            maxFreqValueSpan.textContent = `${maxFreq} Hz`;

            const frequencyResolution = audioContext.sampleRate / analyser.fftSize;

            const minBin = Math.floor(minFreq / frequencyResolution);
            const maxBin = Math.ceil(maxFreq / frequencyResolution);

            const effectiveMinBin = Math.max(0, Math.min(minBin, bufferLength - 1));
            const effectiveMaxBin = Math.min(bufferLength - 1, Math.max(maxBin, effectiveMinBin));

            const visibleBins = effectiveMaxBin - effectiveMinBin + 1;

            if (visibleBins <= 0) {
                ctx.fillStyle = '#e2e8f0';
                ctx.font = '16px Inter';
                ctx.textAlign = 'center';
                ctx.fillText('Adjust frequency range to see data', spectrographCanvas.width / 2, spectrographCanvas.height / 2);
                detectedNoteSpan.textContent = 'N/A';
                animationFrameId = requestAnimationFrame(updateSpectrograph);
                return;
            }

            const freqRangeHeight = maxFreq - minFreq;
            const pixelsPerHz = spectrographCanvas.height / freqRangeHeight;

            let dominantFrequency = 0;
            let maxMagnitude = 0;

            // Update seek bar for file playback
            if (isPlayingFile && audioBuffer) {
                playbackTime = audioContext.currentTime - startTime;
                if (playbackTime >= audioBuffer.duration) {
                    // Audio has ended, stop everything
                    stopAllSources();
                    statusMessage.textContent = `Finished playing: ${selectedAudioFile.name}.`;
                    playSelectedAudioBtn.textContent = 'Play / Pause Audio';
                    return; // Exit update loop
                }
                seekBar.value = playbackTime;
                progressTimeSpan.textContent = `${formatTime(playbackTime)} / ${formatTime(audioBuffer.duration)}`;
            } else if (micSource) {
                 progressTimeSpan.textContent = `Live / --:--`;
            }


            // Iterate through the buffer and draw each column
            spectrographBuffer.forEach((columnData, x_pos) => {
                // For the dominant frequency, we only care about the *latest* frame
                if (x_pos === spectrographBuffer.length - 1) { // If it's the last column
                    for (let i = effectiveMinBin; i <= effectiveMaxBin; i++) {
                        const freq = i * frequencyResolution;
                        const magnitude = columnData[i];
                        if (magnitude > maxMagnitude) {
                            maxMagnitude = magnitude;
                            dominantFrequency = freq;
                        }
                    }
                }

                for (let i = effectiveMinBin; i <= effectiveMaxBin; i++) {
                    const freq = i * frequencyResolution;
                    const magnitude = columnData[i];

                    let r = Math.floor(magnitude * 1);
                    let g = Math.floor(magnitude * 0.5);
                    let b = Math.floor(magnitude * 0.2);
                    ctx.fillStyle = `rgb(${r}, ${g}, ${b})`;

                    const y_start = spectrographCanvas.height - ((freq - minFreq) * pixelsPerHz);
                    const y_end = spectrographCanvas.height - (((freq + frequencyResolution) - minFreq) * pixelsPerHz);

                    const drawY = Math.min(y_start, y_end);
                    const drawHeight = Math.abs(y_start - y_end);

                    if (drawY + drawHeight > 0 && drawY < spectrographCanvas.height) {
                       ctx.fillRect(x_pos, drawY, 1, drawHeight);
                    }
                }
            });


            // --- Draw Frequency Grid Overlay ---
            if (isOverlayVisible) {
                const tickFrequencies = [
                    50, 100, 200, 300, 400, 500, 600, 700, 800, 900,
                    1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000,
                    10000, 12000, 14000, 16000, 18000, 20000
                ];

                ctx.font = '12px Inter';
                ctx.fillStyle = '#a0aec0';
                ctx.strokeStyle = 'rgba(160, 174, 192, 0.3)';
                ctx.lineWidth = 0.5;

                tickFrequencies.forEach(freq => {
                    if (freq >= minFreq && freq <= maxFreq) {
                        const y_pos = spectrographCanvas.height - ((freq - minFreq) * pixelsPerHz);

                        if (y_pos >= 0 && y_pos <= spectrographCanvas.height) {
                            ctx.beginPath();
                            ctx.moveTo(0, y_pos);
                            ctx.lineTo(spectrographCanvas.width, y_pos);
                            ctx.stroke();

                            let label = freq + ' Hz';
                            if (freq >= 1000) {
                                label = (freq / 1000) + ' kHz';
                            }
                            ctx.textAlign = 'left';
                            ctx.fillText(label, 5, y_pos - 2);
                        }
                    }
                });
            }
            // --- End Draw Frequency Grid Overlay ---

            // --- Display Detected Note ---
            if (isOverlayVisible && dominantFrequency > 0 && maxMagnitude > 0) {
                const detectedNote = getNoteFromFrequency(dominantFrequency);
                detectedNoteSpan.textContent = `${detectedNote} (${dominantFrequency.toFixed(2)} Hz)`;

                const dominantFreqY = spectrographCanvas.height - ((dominantFrequency - minFreq) * pixelsPerHz);
                if (dominantFreqY >= 0 && dominantFreqY <= spectrographCanvas.height) {
                    ctx.strokeStyle = dominantFreqLineColor;
                    ctx.lineWidth = dominantFreqLineWidth;
                    ctx.beginPath();
                    ctx.moveTo(0, dominantFreqY);
                    ctx.lineTo(spectrographCanvas.width, dominantFreqY);
                    ctx.stroke();

                    ctx.fillStyle = dominantFreqLabelColor;
                    ctx.font = dominantFreqLabelFont;
                    ctx.textAlign = 'right';
                    ctx.fillText(`${detectedNote}`, spectrographCanvas.width + dominantFreqLabelOffsetX, dominantFreqY + dominantFreqLabelOffsetY);
                }
            } else {
                detectedNoteSpan.textContent = 'N/A';
            }
            // --- End Display Detected Note ---

            animationFrameId = requestAnimationFrame(updateSpectrograph);
        }

        // Event listener for audio file input
        audioFile.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                loadAudioFile(file); // Load, but don't auto-play
            } else {
                selectedAudioFile = null;
                audioBuffer = null;
                statusMessage.textContent = 'No audio file selected.';
                playSelectedAudioBtn.disabled = true;
                startRecordingBtn.disabled = true;
                stopAllAudioBtn.disabled = true;
                detectedNoteSpan.textContent = 'N/A';
                seekBar.disabled = true;
                progressTimeSpan.textContent = `0:00 / 0:00`;
            }
        });

        // Event listener for "Play Selected Audio" button (now Play/Pause)
        playSelectedAudioBtn.addEventListener('click', togglePlayPauseFile);

        // Event listener for microphone button
        startMicrophoneBtn.addEventListener('click', () => {
            startMicrophone();
        });

        // Event listeners for recording buttons
        startRecordingBtn.addEventListener('click', startRecording);
        stopRecordingBtn.addEventListener('click', stopRecording);

        // Event listener for saving spectrogram image
        saveSpectrogramBtn.addEventListener('click', saveSpectrogramImage);

        // Event listener for stop all audio button
        stopAllAudioBtn.addEventListener('click', stopAllSources);

        // Event listener for A4=432Hz button
        setA432HzBtn.addEventListener('click', () => {
            const newMinFreq = 400;
            const newMaxFreq = 500;

            minFreqSlider.value = newMinFreq;
            maxFreqSlider.value = newMaxFreq;
            minFreqNumberInput.value = newMinFreq;
            maxFreqNumberInput.value = newMaxFreq;

            minFreqValueSpan.textContent = `${newMinFreq} Hz`;
            maxFreqValueSpan.textContent = `${newMaxFreq} Hz`;
        });

        // Event listener for Toggle Overlay button
        toggleOverlayBtn.addEventListener('click', () => {
            isOverlayVisible = !isOverlayVisible;
            if (audioContext && (fileSource || micSource)) {
                // If audio is playing, the animation frame will handle the redraw
            } else {
                ctx.clearRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
                ctx.fillStyle = '#000';
                ctx.fillRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
                if (spectrographBuffer.length > 0) {
                     updateSpectrograph();
                }
            }
        });

        // Event listener for Volume Slider
        volumeSlider.addEventListener('input', () => {
            if (gainNode) {
                gainNode.gain.value = parseFloat(volumeSlider.value);
                volumeValueSpan.textContent = `${Math.round(parseFloat(volumeSlider.value) * 100)}%`;
            }
        });

        // Event listener for Seek Bar
        seekBar.addEventListener('input', () => {
            if (audioBuffer && !isPaused) { // Only seek if an audio file is loaded and not paused
                // Stop current playback
                if (fileSource) {
                    fileSource.stop();
                    fileSource.disconnect();
                    fileSource = null;
                }
                // Update playbackTime to the new seek position
                playbackTime = parseFloat(seekBar.value);
                // Start playback from the new position
                playAudioFile(playbackTime);
            }
        });


        // Event listeners for frequency range sliders
        minFreqSlider.addEventListener('input', () => {
            let newMin = parseFloat(minFreqSlider.value);
            let currentMax = parseFloat(maxFreqSlider.value);
            if (newMin >= currentMax) {
                newMin = currentMax - 10;
                minFreqSlider.value = newMin;
            }
            minFreqNumberInput.value = newMin;
            minFreqValueSpan.textContent = `${newMin} Hz`;
        });

        maxFreqSlider.addEventListener('input', () => {
            let newMax = parseFloat(maxFreqSlider.value);
            let currentMin = parseFloat(minFreqSlider.value);
            if (newMax <= currentMin) {
                newMax = currentMin + 10;
                maxFreqSlider.value = newMax;
            }
            maxFreqNumberInput.value = newMax;
            maxFreqValueSpan.textContent = `${newMax} Hz`;
        });

        // Event listeners for number inputs
        minFreqNumberInput.addEventListener('change', () => {
            let newMin = parseFloat(minFreqNumberInput.value);
            let currentMax = parseFloat(maxFreqNumberInput.value);
            const minAllowed = parseFloat(minFreqNumberInput.min);
            const maxAllowed = parseFloat(minFreqNumberInput.max);

            if (isNaN(newMin) || newMin < minAllowed) {
                newMin = minAllowed;
            } else if (newMin >= currentMax) {
                newMin = currentMax - 10;
            } else if (newMin > maxAllowed) {
                newMin = maxAllowed;
            }
            minFreqNumberInput.value = newMin;
            minFreqSlider.value = newMin;
            minFreqValueSpan.textContent = `${newMin} Hz`;
        });

        maxFreqNumberInput.addEventListener('change', () => {
            let newMax = parseFloat(maxFreqNumberInput.value);
            let currentMin = parseFloat(minFreqNumberInput.value);
            const minAllowed = parseFloat(maxFreqNumberInput.min);
            const maxAllowed = parseFloat(maxFreqNumberInput.max);

            if (isNaN(newMax) || newMax > maxAllowed) {
                newMax = maxAllowed;
            } else if (newMax <= currentMin) {
                newMax = currentMin + 10;
            } else if (newMax < minAllowed) {
                newMax = minAllowed;
            }
            maxFreqNumberInput.value = newMax;
            maxFreqSlider.value = newMax;
            maxFreqValueSpan.textContent = `${newMax} Hz`;
        });


        // Initial setup for canvas size
        function resizeCanvas() {
            spectrographCanvas.width = spectrographCanvas.offsetWidth;
            spectrographCanvas.height = spectrographCanvas.offsetHeight;
            spectrographBuffer = [];
            if (audioContext && (fileSource || micSource)) {
                 if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                 }
                 updateSpectrograph();
            } else {
                 ctx.clearRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
                 ctx.fillStyle = '#000';
                 ctx.fillRect(0, 0, spectrographCanvas.width, spectrographCanvas.height);
            }
        }

        // Call resizeCanvas initially and on window resize
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas(); // Initial call

        // Disable buttons initially
        startRecordingBtn.disabled = true;
        stopRecordingBtn.disabled = true;
        stopAllAudioBtn.disabled = true;
        playSelectedAudioBtn.disabled = true; // Still disabled until a file is selected

        // Stop animation and audio when page is closed or navigation occurs
        window.addEventListener('beforeunload', () => {
            stopAllSources();
            if (analyser) {
                analyser.disconnect();
            }
            if (gainNode) { // Disconnect gainNode too
                gainNode.disconnect();
            }
            if (audioContext) {
                audioContext.close();
            }
        });
    </script>
</body>
</html>
